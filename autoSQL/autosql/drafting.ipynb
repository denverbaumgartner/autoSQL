{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from data import SQLData\n",
    "from _decimal import Decimal\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from datasets import DatasetDict, Dataset\n",
    "#from predict import SQLPredict\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "# Now you can get the loaded environment variable using os.environ\n",
    "GITHUB_GIST_TOKEN = os.environ.get(\"GITHUB_GIST_TOKEN\")\n",
    "REPLICATE_API_TOKEN = os.environ.get(\"REPLICATE_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'b-mc2/sql-create-context'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b07e7b4470cc43b9bdd4dee2c335a71e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/3.16k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80dd0ff45e59430e95add49687c34f66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec32b507399c4f5f8d8ac73d51890c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/21.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29bedf6c391a4cbc879200a194f42204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74f21e3021a7457780e7748450f5c55f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sq = SQLData.from_sql_create_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT artist FROM table_name_29 WHERE mintage > 34 OFFSET 135\n",
      "{'context': 'CREATE TABLE table_name_29 (artist VARCHAR, mintage INTEGER)', 'question': 'What artist has a mintage of greater than 34,135?', 'answer': 'SELECT artist FROM table_name_29 WHERE mintage > 34 OFFSET 135'}\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(sq.data[name]['train'])):\n",
    "\n",
    "    answer = sq.data[name]['train'][i]['answer']\n",
    "\n",
    "    if answer == 'SELECT artist FROM table_name_29 WHERE mintage > 34 OFFSET 135': \n",
    "        print(answer)\n",
    "        print(sq.data[name]['train'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.preprocess_data(dataset_name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.filter_data(dataset_name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.data[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.train_test_split(dataset_name=name, new_dataset_name=\"data_llama_13b_1_0_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.data[\"data_llama_13b_1_0_0\"]['test'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_resp = sq.upload_jsonl_gist(\n",
    "    dataset_name=\"data_llama_13b_1_0_0\",\n",
    "    token=GITHUB_GIST_TOKEN,\n",
    "    filename=\"training_data_llama_13b_1_0_0.jsonl\",\n",
    "    description=\"Training data for the first version of the llama_13b (1.0.0) model\",\n",
    ")\n",
    "training_resp['files']['training_data_llama_13b_1_0_0.jsonl']['raw_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_resp = sq.upload_jsonl_gist(\n",
    "    dataset_name=\"data_llama_13b_1_0_0\",\n",
    "    token=GITHUB_GIST_TOKEN,\n",
    "    filename=\"testing_data_llama_13b_1_0_0.jsonl\",\n",
    "    dataset_type=\"test\",\n",
    "    description=\"Testing data for the first version of the llama_13b (1.0.0) model\",\n",
    ")\n",
    "testing_resp['files']['testing_data_llama_13b_1_0_0.jsonl']['raw_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.data[\"data_llama_13b_1_0_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.data[\"data_llama_13b_1_0_0\"].save_to_disk(\"data_llama_13b_1_0_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import sqlglot\n",
    "import replicate\n",
    "import datasets\n",
    "from replicate import Client as rc\n",
    "from _decimal import Decimal\n",
    "from dotenv import load_dotenv\n",
    "from datasets import DatasetDict, Dataset\n",
    "from sqlglot.executor import execute\n",
    "\n",
    "from data import SQLData\n",
    "from predict import SQLPredict\n",
    "from eval import SQLEval\n",
    "\n",
    "from sqlglot.errors import (\n",
    "    ExecuteError,\n",
    "    TokenError,\n",
    "    SchemaError,\n",
    "    ExecuteError,\n",
    "    ParseError,\n",
    "    UnsupportedError,\n",
    "    SqlglotError,\n",
    "    OptimizeError,\n",
    ")\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "# Now you can get the loaded environment variable using os.environ\n",
    "GITHUB_GIST_TOKEN = os.environ.get(\"GITHUB_GIST_TOKEN\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "REPLICATE_API_TOKEN = os.environ.get(\"REPLICATE_API_TOKEN\")\n",
    "REPLICATE_LLAMA_7B_TUNED = os.environ.get(\"REPLICATE_LLAMA_7B_TUNED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqp = SQLPredict(OPENAI_API_KEY, REPLICATE_API_TOKEN)\n",
    "sqp = SQLPredict.from_replicate_model(\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    replicate_api_key=REPLICATE_API_TOKEN,\n",
    "    model_name=\"llama_2_13b_sql\",\n",
    "    model_id=REPLICATE_LLAMA_7B_TUNED\n",
    ")\n",
    "sqd = SQLData.from_sql_create_context()\n",
    "sqe = SQLEval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqd.data[\"data_llama_13b_1_0_0\"] = DatasetDict.load_from_disk(\"../local_data/data_llama_13b_1_0_0/\")\n",
    "sqd.data[\"data_llama_13b_1_0_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rich_testing = sqd.data[\"data_llama_13b_1_0_0\"]['test'].filter(lambda example: example['query_result'] != '[]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rich_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rich_testing = rich_testing.filter(lambda example: example['query_result'] != '[(0,)]' and example['query_result'] != '[(None,)]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rich_testing.filter(lambda example: example['query_result'] == '[(None,)]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rich_testing[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rich_testing.save_to_disk(\"rich_testing_llama_13b_1_0_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rich_testing = Dataset.load_from_disk(\"../local_data/rich_testing_llama_13b_1_0_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rich_testing = rich_testing.filter(lambda example: example['query_result'] != '[(0,)]' and example['query_result'] != '[(None,)]' and example['query_result'] != '[]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rich_testing_subset_0_100 = rich_testing.select(range(0, 100))\n",
    "rich_testing_subset_100_200 = rich_testing.select(range(100, 200))\n",
    "rich_testing_subset_200_300 = rich_testing.select(range(200, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rich_testing_subset = datasets.concatenate_datasets([rich_testing_subset_0_100, rich_testing_subset_100_200, rich_testing_subset_200_300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rich_testing_subset_0_100 = rich_testing_subset_0_100.map(sqp.openai_dataset_request)\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rich_testing_subset_100_200 = rich_testing_subset_100_200.map(sqp.openai_dataset_request)\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rich_testing_subset = rich_testing_subset.map(sqp.openai_dataset_request)\n",
    "rich_testing_subset_200_300 = rich_testing_subset_200_300.map(sqp.openai_dataset_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rich_testing_subset = rich_testing_subset.map(sqe.validate_openai_query)\n",
    "rich_testing_subset_0_100 = rich_testing_subset_0_100.map(sqe.validate_openai_query)\n",
    "rich_testing_subset_100_200 = rich_testing_subset_100_200.map(sqe.validate_openai_query)\n",
    "rich_testing_subset_200_300 = rich_testing_subset_200_300.map(sqe.validate_openai_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rich_testing_subset = rich_testing_subset.map(sqd.format_tuning_data)\n",
    "\n",
    "rich_testing_subset_0_100 = rich_testing_subset_0_100.map(sqd.format_tuning_data)\n",
    "rich_testing_subset_100_200 = rich_testing_subset_100_200.map(sqd.format_tuning_data)\n",
    "rich_testing_subset_200_300 = rich_testing_subset_200_300.map(sqd.format_tuning_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rich_testing_subset_0_100 = rich_testing_subset_0_100.map(sqp.replicate_dataset_request)\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rich_testing_subset_100_200 = rich_testing_subset_100_200.map(sqp.replicate_dataset_request)\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rich_testing_subset_200_300 = rich_testing_subset_200_300.map(sqp.replicate_dataset_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rich_testing_subset = datasets.concatenate_datasets([rich_testing_subset_0_100, rich_testing_subset_100_200, rich_testing_subset_200_300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rich_testing_subset.save_to_disk(\"rich_testing_subset_llama_13b_1_0_0_inferences_two\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rich_testing_subset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_test = Dataset.load_from_disk(\"rich_testing_subset_llama_13b_1_0_0_inferences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rich_testing_subset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rich_testing_subset[0]['tuning_format']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(rich_testing_subset[0]['tuning_format'])['prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_client = rc(api_token=REPLICATE_API_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = rep_client.run(\n",
    "    \"denverbaumgartner/llama-2-13b-sql:6318cb7d0fce8e4b19262e8aa946a53781d7ca9a56ba8e5c6afc067074d33902\",\n",
    "    input={\"prompt\": \"hello, world\"},\n",
    ")\n",
    "# The denverbaumgartner/llama-2-13b-sql model can stream output as it's running.\n",
    "# The predict method returns an iterator, and you can iterate over that output.\n",
    "for item in output:\n",
    "    # https://replicate.com/denverbaumgartner/llama-2-13b-sql/versions/6318cb7d0fce8e4b19262e8aa946a53781d7ca9a56ba8e5c6afc067074d33902/api#output-schema\n",
    "    print(item, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = rc.run(\n",
    "    \"denverbaumgartner/llama-2-13b-sql:6318cb7d0fce8e4b19262e8aa946a53781d7ca9a56ba8e5c6afc067074d33902\",\n",
    "    input={\"prompt\": \"hello, world\"},\n",
    ")\n",
    "# The denverbaumgartner/llama-2-13b-sql model can stream output as it's running.\n",
    "# The predict method returns an iterator, and you can iterate over that output.\n",
    "for item in output:\n",
    "    # https://replicate.com/denverbaumgartner/llama-2-13b-sql/versions/6318cb7d0fce8e4b19262e8aa946a53781d7ca9a56ba8e5c6afc067074d33902/api#output-schema\n",
    "    print(item, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = replicate.run(\n",
    "    \"denverbaumgartner/llama-2-13b-sql:6318cb7d0fce8e4b19262e8aa946a53781d7ca9a56ba8e5c6afc067074d33902\",\n",
    "    input={\"prompt\": \"[INST] <<SYS>>\\nContext contains the relevant SQL tables, provide the query that answers the Question in response.\\n<</SYS>>\\n\\nContext: CREATE TABLE table_211714_2 (rank VARCHAR, viewers__in_millions_ VARCHAR)\\n\\nQuestion: Name the rank for 14.80 viewers[/INST]\\n\\n\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_string = ''.join(item for item in output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"SELECT.*?\\n\\n\"\n",
    "matches = re.findall(pattern, output_string, re.DOTALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in output:\n",
    "    # https://replicate.com/denverbaumgartner/llama-2-13b-sql/versions/6318cb7d0fce8e4b19262e8aa946a53781d7ca9a56ba8e5c6afc067074d33902/api#output-schema\n",
    "    print(item, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for match in matches:\n",
    "    print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import sqlglot\n",
    "import replicate\n",
    "import datasets\n",
    "from replicate import Client as rc\n",
    "from _decimal import Decimal\n",
    "from dotenv import load_dotenv\n",
    "from datasets import DatasetDict, Dataset\n",
    "from sqlglot.executor import execute\n",
    "\n",
    "from data import SQLData\n",
    "from predict import SQLPredict\n",
    "from eval import SQLEval\n",
    "\n",
    "from sqlglot.errors import (\n",
    "    ExecuteError,\n",
    "    TokenError,\n",
    "    SchemaError,\n",
    "    ExecuteError,\n",
    "    ParseError,\n",
    "    UnsupportedError,\n",
    "    SqlglotError,\n",
    "    OptimizeError,\n",
    ")\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "# Now you can get the loaded environment variable using os.environ\n",
    "GITHUB_GIST_TOKEN = os.environ.get(\"GITHUB_GIST_TOKEN\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "REPLICATE_API_TOKEN = os.environ.get(\"REPLICATE_API_TOKEN\")\n",
    "REPLICATE_LLAMA_7B_TUNED = os.environ.get(\"REPLICATE_LLAMA_7B_TUNED\")\n",
    "\n",
    "# sqp = SQLPredict(OPENAI_API_KEY, REPLICATE_API_TOKEN)\n",
    "sqp = SQLPredict.from_replicate_model(\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    replicate_api_key=REPLICATE_API_TOKEN,\n",
    "    model_name=\"llama_2_13b_sql\",\n",
    "    model_id=REPLICATE_LLAMA_7B_TUNED\n",
    ")\n",
    "sqd = SQLData.from_sql_create_context()\n",
    "sqe = SQLEval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_data = Dataset.load_from_disk(\"../local_data/rich_testing_subset_llama_13b_1_0_0_inferences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = inf_data.map(sqe.validate_replicate_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.filter(lambda example: example['replicate_valid'] == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.filter(lambda example: example['openai_valid'] == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_wrong = test.filter(lambda example: example['replicate_valid'] == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = rep_wrong[0]['replicate_inference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"SELECT.*?\\n\\n\"\n",
    "matches = re.findall(pattern, resp, re.DOTALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replicate_response_parser(dataset):\n",
    "    \n",
    "    replicate_inference = dataset['replicate_inference']\n",
    "    replicate_result = dataset['replicate_result']\n",
    "    \n",
    "    tables = json.loads(dataset['filler_data'])\n",
    "    \n",
    "    pattern = r\"SELECT.*?(?=\\n|\\[/|,\\[INST\\])\"\n",
    "    matches = re.findall(pattern, replicate_inference, re.DOTALL)\n",
    "    \n",
    "    result = None\n",
    "    valid_result = None \n",
    "    valid_statement = None\n",
    "    \n",
    "    for match in matches:\n",
    "        try: \n",
    "            result = execute(match, tables=tables)\n",
    "            if result.rows is not None: \n",
    "                valid_result = str(result.rows)\n",
    "                valid_statement = match\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    if valid_result and valid_statement: \n",
    "        dataset['replicate_inference'] = valid_statement \n",
    "        dataset['replicate_result'] = valid_result \n",
    "        dataset['replicate_valid'] = True\n",
    "    else: \n",
    "        dataset['replicate_inference'] = replicate_inference \n",
    "        dataset['replicate_result'] = replicate_result\n",
    "        dataset['replicate_valid'] = False\n",
    "    return dataset\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_wrong_c = rep_wrong.map(replicate_response_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_wrong_b = rep_wrong_c.filter(lambda example: example['replicate_valid'] == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_wrong_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_wrong_b[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_wrong_b[0]['replicate_inference'].replace('Query:', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = rep_wrong_c[0]['replicate_inference']\n",
    "tables = json.loads(rep_wrong_c[0]['filler_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = execute(query, tables=tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_newline_query(dataset):\n",
    "\n",
    "    substrings_to_replace = [\"```\", \"\\nQuery:\", \"\\n\", \"SQL>\"]\n",
    "    query_string = dataset[\"replicate_inference\"]\n",
    "\n",
    "    for substring in substrings_to_replace:\n",
    "        query_string = query_string.replace(substring, \"\")\n",
    "\n",
    "    return {\"replicate_inference\": query_string}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autosql",
   "language": "python",
   "name": "autosql"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

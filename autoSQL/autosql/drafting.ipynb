{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlglot\n",
    "from sqlglot.executor import execute\n",
    "from sqlglot.errors import ExecuteError, TokenError, SchemaError, ExecuteError, ParseError, UnsupportedError, SqlglotError, OptimizeError\n",
    "\n",
    "import json\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from faker import Faker\n",
    "import json\n",
    "\n",
    "# Initialize a Faker instance\n",
    "fake = Faker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import SQLData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn = 'b-mc2/sql-create-context'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataz = SQLData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataz.load_data(dataset_name=sn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('b-mc2/sql-create-context')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['answer', 'context', 'question'],\n",
       "        num_rows: 78577\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating a new column\n",
    "\n",
    "```python\n",
    "def compute_review_length(example):\n",
    "    return {\"review_length\": len(example[\"review\"].split())}\n",
    "\n",
    "drug_dataset = drug_dataset.map(compute_review_length)\n",
    "```\n",
    "\n",
    "alternatively \n",
    "\n",
    "```python \n",
    "drug_dataset = drug_dataset.add_column(list)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_table_count(dataset): \n",
    "    count = len(dataset['context'].split(';'))\n",
    "    return {\"table_count\": count}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abstract_column_types(dataset): \n",
    "    \n",
    "    atls = sqlglot.parse(dataset['context'])\n",
    "    tables = {}\n",
    "\n",
    "    for atl in atls:\n",
    "        column_types = {}\n",
    "        table_name = atl.find(sqlglot.expressions.Identifier).this\n",
    "        for expr in atl.this.expressions:\n",
    "            column_name = expr.find(sqlglot.expressions.Identifier).this\n",
    "            column_type = expr.find(sqlglot.expressions.DataType).this.value\n",
    "            column_types[column_name] = column_type\n",
    "        tables[table_name] = column_types\n",
    "\n",
    "    return {\"column_types\": json.dumps(tables)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_duplicate_create_table(dataset): \n",
    "\n",
    "    create_count = dataset['table_count']\n",
    "    table_count = len(json.loads(dataset['column_types']).keys())\n",
    "\n",
    "    if create_count == table_count:\n",
    "        return {\"duplicate_create_table\": False}\n",
    "    else:\n",
    "        return {\"duplicate_create_table\": True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"station\": [\n",
      "        {\n",
      "            \"name\": \"Timothy Butler\",\n",
      "            \"id\": \"Shaun Douglas\",\n",
      "            \"installation_date\": \"Linda Owens\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Amy Wood\",\n",
      "            \"id\": \"Jennifer Coleman\",\n",
      "            \"installation_date\": \"James Baker\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Shaun Moreno\",\n",
      "            \"id\": \"Mark Moses\",\n",
      "            \"installation_date\": \"Pamela Beltran\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Shari Tucker\",\n",
      "            \"id\": \"Lauren Mack\",\n",
      "            \"installation_date\": \"Christina Tucker\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"James Goodman\",\n",
      "            \"id\": \"Benjamin Williams\",\n",
      "            \"installation_date\": \"David Craig\"\n",
      "        }\n",
      "    ],\n",
      "    \"status\": [\n",
      "        {\n",
      "            \"station_id\": \"Edward Hamilton\",\n",
      "            \"bikes_available\": 81\n",
      "        },\n",
      "        {\n",
      "            \"station_id\": \"Jasmine Griffin\",\n",
      "            \"bikes_available\": 99\n",
      "        },\n",
      "        {\n",
      "            \"station_id\": \"William Rodriguez\",\n",
      "            \"bikes_available\": 67\n",
      "        },\n",
      "        {\n",
      "            \"station_id\": \"Michael Lowe\",\n",
      "            \"bikes_available\": 8\n",
      "        },\n",
      "        {\n",
      "            \"station_id\": \"Larry Riley\",\n",
      "            \"bikes_available\": 6\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Your column types data\n",
    "column_types_data = '{\"station\": {\"name\": \"VARCHAR\", \"id\": \"VARCHAR\", \"installation_date\": \"VARCHAR\"}, \"status\": {\"station_id\": \"VARCHAR\", \"bikes_available\": \"INT\"}}'\n",
    "column_types = json.loads(column_types_data)\n",
    "\n",
    "def generate_random_data(data_type):\n",
    "    if data_type == \"VARCHAR\":\n",
    "        return fake.name()\n",
    "    elif data_type == \"INT\":\n",
    "        return fake.random_int(min=1, max=100)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def generate_filler_data(column_types, num_records=5):\n",
    "    filler_data = {}\n",
    "    \n",
    "    for table_name, columns in column_types.items():\n",
    "        filler_data[table_name] = []\n",
    "        \n",
    "        for _ in range(num_records):\n",
    "            record = {}\n",
    "            for column_name, data_type in columns.items():\n",
    "                record[column_name] = generate_random_data(data_type)\n",
    "            filler_data[table_name].append(record)\n",
    "    \n",
    "    return filler_data\n",
    "\n",
    "def populate_data(dataset): \n",
    "\n",
    "    column_types = json.loads(dataset['column_types'])\n",
    "    return {\"filler_data\": json.dumps(generate_filler_data(column_types))}\n",
    "\n",
    "# Generate filler data\n",
    "filler_data = generate_filler_data(column_types)\n",
    "print(json.dumps(filler_data, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blanket_answer_syntax(dataset):\n",
    "\n",
    "    answer = dataset['answer'].replace('\"', \"'\")\n",
    "    return {\"answer\": answer}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_query(dataset): \n",
    "\n",
    "    tables = json.loads(dataset['filler_data'])\n",
    "    query = dataset['answer']\n",
    "\n",
    "    try:\n",
    "        result = execute(query, tables=tables)\n",
    "        result = str(result.rows)\n",
    "        if result == None:\n",
    "            result = ''\n",
    "        return {\"query_result\": result, \"valid_query\": True}\n",
    "    except ExecuteError as e:\n",
    "        return {\"query_result\": \"ExecuteError\", \"valid_query\": False}\n",
    "    except OptimizeError as e:\n",
    "        return {\"query_result\": \"OptimizeError\", \"valid_query\": False}\n",
    "    except TokenError as e:\n",
    "        return {\"query_result\": \"TokenError\", \"valid_query\": False}\n",
    "    except SchemaError as e:\n",
    "        return {\"query_result\": \"SchemaError\", \"valid_query\": False}\n",
    "    except ParseError as e:\n",
    "        return {\"query_result\": \"ParseError\", \"valid_query\": False}\n",
    "    except UnsupportedError as e:\n",
    "        return {\"query_result\": \"UnsupportedError\", \"valid_query\": False}\n",
    "    except SqlglotError as e: \n",
    "        return {\"query_result\": \"SqlglotError\", \"valid_query\": False}\n",
    "    except Exception as e:\n",
    "        return {\"query_result\": str(e), \"valid_query\": False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(compute_table_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(abstract_column_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(identify_duplicate_create_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41a2548faca04f5693a8027b1729f465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/78577 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(populate_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a96d89faf4e4d188a26c69b65a401d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/78577 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(blanket_answer_syntax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ff2aadf8dde4d848f41412411d949ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/78577 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LT(1996[2], 726):1: SyntaxWarning: 'int' object is not subscriptable; perhaps you missed a comma?\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(validate_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1199b9d707a8457298fdbbf2210b0551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/78577 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get a count of invalid queries\n",
    "invalid_queries = dataset['train'].filter(lambda x: x['valid_query'] == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65a3401ac1f54c7cbad05900ed2a3d05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/78577 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_error = dataset['train'].filter(lambda x: x['query_result'] == \"OptimizeError\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': \"SELECT T1.name, T1.id FROM station AS T1 JOIN status AS T2 ON T1.id = T2.station_id GROUP BY T2.station_id HAVING AVG(T2.bikes_available) > 14 UNION SELECT name, id FROM station WHERE installation_date LIKE '12/%'\",\n",
       " 'context': 'CREATE TABLE station (name VARCHAR, id VARCHAR); CREATE TABLE station (name VARCHAR, id VARCHAR, installation_date VARCHAR); CREATE TABLE status (station_id VARCHAR, bikes_available INTEGER)',\n",
       " 'question': 'What are the names and ids of stations that had more than 14 bikes available on average or were installed in December?',\n",
       " 'table_count': 3,\n",
       " 'column_types': '{\"station\": {\"name\": \"VARCHAR\", \"id\": \"VARCHAR\", \"installation_date\": \"VARCHAR\"}, \"status\": {\"station_id\": \"VARCHAR\", \"bikes_available\": \"INT\"}}',\n",
       " 'duplicate_create_table': True,\n",
       " 'filler_data': '{\"station\": [{\"name\": \"Emily Nichols\", \"id\": \"Colleen Roth\", \"installation_date\": \"Andres Lopez\"}, {\"name\": \"Patrick Duncan\", \"id\": \"Spencer Miller\", \"installation_date\": \"Kevin Carroll\"}, {\"name\": \"John Campos\", \"id\": \"Sean Johns\", \"installation_date\": \"Jerry Adams\"}, {\"name\": \"Thomas Green\", \"id\": \"Stacey Rivera\", \"installation_date\": \"David Hutchinson\"}, {\"name\": \"David Jenkins\", \"id\": \"Rita Davis\", \"installation_date\": \"Marcus Morgan\"}], \"status\": [{\"station_id\": \"Shelly Wheeler\", \"bikes_available\": 21}, {\"station_id\": \"Emma Smith\", \"bikes_available\": 42}, {\"station_id\": \"Kevin Herman\", \"bikes_available\": 55}, {\"station_id\": \"Samuel Rodriguez\", \"bikes_available\": 96}, {\"station_id\": \"Frank Hall DDS\", \"bikes_available\": 21}]}',\n",
       " 'query_result': '[]',\n",
       " 'valid_query': True}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SELECT T1.name, T1.id FROM station AS T1 JOIN status AS T2 ON T1.id = T2.station_id GROUP BY T2.station_id HAVING AVG(T2.bikes_available) > 14 UNION SELECT name, id FROM station WHERE installation_date LIKE '12/%'\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][80]['answer'].replace('\"', \"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'SELECT DISTINCT zip_code FROM weather EXCEPT SELECT DISTINCT zip_code FROM weather WHERE max_dew_point_f >= 70',\n",
       " 'context': 'CREATE TABLE weather (zip_code VARCHAR, max_dew_point_f VARCHAR)',\n",
       " 'question': 'Find all the zip codes in which the max dew point have never reached 70.',\n",
       " 'table_count': 1,\n",
       " 'column_types': '{\"weather\": {\"zip_code\": \"VARCHAR\", \"max_dew_point_f\": \"VARCHAR\"}}',\n",
       " 'duplicate_create_table': False,\n",
       " 'filler_data': '{\"weather\": [{\"zip_code\": \"Juan Gentry\", \"max_dew_point_f\": \"Karen Rodriguez\"}, {\"zip_code\": \"Kevin Ritter\", \"max_dew_point_f\": \"Douglas Garza\"}, {\"zip_code\": \"Angela Smith\", \"max_dew_point_f\": \"Robert Combs\"}, {\"zip_code\": \"Julia Velazquez\", \"max_dew_point_f\": \"Carrie Knapp DDS\"}, {\"zip_code\": \"Rachel Simmons\", \"max_dew_point_f\": \"Gail Hayes\"}]}',\n",
       " 'query_result': 'ExecuteError',\n",
       " 'valid_query': False}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invalid_queries[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = check_error[5]['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SELECT T2.student_id FROM courses AS T1 JOIN student_course_registrations AS T2 ON T1.course_id = T2.course_id WHERE T1.course_name = 'statistics' ORDER BY T2.registration_date\""
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.replace('\"', \"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'table_name_51': [{'pick': 'Emily Potter',\n",
       "   'college_high_school_club': 'Dr. Megan Coleman MD',\n",
       "   'round': 'Rodney Bridges',\n",
       "   'draft': 'David Lucas'},\n",
       "  {'pick': 'Beverly Mendoza',\n",
       "   'college_high_school_club': 'Tiffany Chen',\n",
       "   'round': 'Jonathan Baker',\n",
       "   'draft': 'Deborah Rodriguez'},\n",
       "  {'pick': 'Stephanie Burgess',\n",
       "   'college_high_school_club': 'Sandra Morgan',\n",
       "   'round': 'Mr. Donald Gray',\n",
       "   'draft': 'Michelle Mcdonald'},\n",
       "  {'pick': 'Bonnie Frank',\n",
       "   'college_high_school_club': 'Angela Edwards',\n",
       "   'round': 'Matthew Joseph',\n",
       "   'draft': 'Rebecca Obrien'},\n",
       "  {'pick': 'Melissa Schmidt',\n",
       "   'college_high_school_club': 'Robert Barnes',\n",
       "   'round': 'Jennifer Pitts',\n",
       "   'draft': 'Mary Schneider'}]}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = json.loads(check_error[41005]['filler_data'])\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Invalid key: 4105 is out of bounds for size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/denver/Documents/alagaesia/yode/autoSQL/autoSQL/autosql/drafting.ipynb Cell 29\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/denver/Documents/alagaesia/yode/autoSQL/autoSQL/autosql/drafting.ipynb#X46sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m query \u001b[39m=\u001b[39m check_error[\u001b[39m4105\u001b[39;49m][\u001b[39m'\u001b[39m\u001b[39manswer\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/denver/Documents/alagaesia/yode/autoSQL/autoSQL/autosql/drafting.ipynb#X46sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m query\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/autosql-L2XNwnQu-py3.11/lib/python3.11/site-packages/datasets/arrow_dataset.py:2803\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2801\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key):  \u001b[39m# noqa: F811\u001b[39;00m\n\u001b[1;32m   2802\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem(key)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/autosql-L2XNwnQu-py3.11/lib/python3.11/site-packages/datasets/arrow_dataset.py:2787\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2785\u001b[0m format_kwargs \u001b[39m=\u001b[39m format_kwargs \u001b[39mif\u001b[39;00m format_kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}\n\u001b[1;32m   2786\u001b[0m formatter \u001b[39m=\u001b[39m get_formatter(format_type, features\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info\u001b[39m.\u001b[39mfeatures, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mformat_kwargs)\n\u001b[0;32m-> 2787\u001b[0m pa_subtable \u001b[39m=\u001b[39m query_table(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data, key, indices\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_indices \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_indices \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m   2788\u001b[0m formatted_output \u001b[39m=\u001b[39m format_table(\n\u001b[1;32m   2789\u001b[0m     pa_subtable, key, formatter\u001b[39m=\u001b[39mformatter, format_columns\u001b[39m=\u001b[39mformat_columns, output_all_columns\u001b[39m=\u001b[39moutput_all_columns\n\u001b[1;32m   2790\u001b[0m )\n\u001b[1;32m   2791\u001b[0m \u001b[39mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/autosql-L2XNwnQu-py3.11/lib/python3.11/site-packages/datasets/formatting/formatting.py:583\u001b[0m, in \u001b[0;36mquery_table\u001b[0;34m(table, key, indices)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    582\u001b[0m     size \u001b[39m=\u001b[39m indices\u001b[39m.\u001b[39mnum_rows \u001b[39mif\u001b[39;00m indices \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m table\u001b[39m.\u001b[39mnum_rows\n\u001b[0;32m--> 583\u001b[0m     _check_valid_index_key(key, size)\n\u001b[1;32m    584\u001b[0m \u001b[39m# Query the main table\u001b[39;00m\n\u001b[1;32m    585\u001b[0m \u001b[39mif\u001b[39;00m indices \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/autosql-L2XNwnQu-py3.11/lib/python3.11/site-packages/datasets/formatting/formatting.py:526\u001b[0m, in \u001b[0;36m_check_valid_index_key\u001b[0;34m(key, size)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mint\u001b[39m):\n\u001b[1;32m    525\u001b[0m     \u001b[39mif\u001b[39;00m (key \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m key \u001b[39m+\u001b[39m size \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m) \u001b[39mor\u001b[39;00m (key \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m size):\n\u001b[0;32m--> 526\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid key: \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m is out of bounds for size \u001b[39m\u001b[39m{\u001b[39;00msize\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    527\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    528\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mslice\u001b[39m):\n",
      "\u001b[0;31mIndexError\u001b[0m: Invalid key: 4105 is out of bounds for size 0"
     ]
    }
   ],
   "source": [
    "query = check_error[4105]['answer']\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "OptimizeError",
     "evalue": "Column '\"western kentucky\"' could not be resolved",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOptimizeError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/Users/denver/Documents/alagaesia/yode/autoSQL/autoSQL/autosql/drafting.ipynb Cell 29\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/denver/Documents/alagaesia/yode/autoSQL/autoSQL/autosql/drafting.ipynb#X50sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m execute(query, tables\u001b[39m=\u001b[39;49mtable)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/autosql-L2XNwnQu-py3.11/lib/python3.11/site-packages/sqlglot/executor/__init__.py:78\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(sql, schema, read, tables)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[39mraise\u001b[39;00m ExecuteError(\u001b[39m\"\u001b[39m\u001b[39mTables must support the same table args as schema\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     77\u001b[0m now \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> 78\u001b[0m expression \u001b[39m=\u001b[39m optimize(sql, schema, leave_tables_isolated\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, dialect\u001b[39m=\u001b[39;49mread)\n\u001b[1;32m     80\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mOptimization finished: \u001b[39m\u001b[39m%f\u001b[39;00m\u001b[39m\"\u001b[39m, time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m now)\n\u001b[1;32m     81\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mOptimized SQL: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, expression\u001b[39m.\u001b[39msql(pretty\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/autosql-L2XNwnQu-py3.11/lib/python3.11/site-packages/sqlglot/optimizer/optimizer.py:92\u001b[0m, in \u001b[0;36moptimize\u001b[0;34m(expression, schema, db, catalog, dialect, rules, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m     rule_params \u001b[39m=\u001b[39m rule\u001b[39m.\u001b[39m\u001b[39m__code__\u001b[39m\u001b[39m.\u001b[39mco_varnames\n\u001b[1;32m     89\u001b[0m     rule_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m     90\u001b[0m         param: possible_kwargs[param] \u001b[39mfor\u001b[39;00m param \u001b[39min\u001b[39;00m rule_params \u001b[39mif\u001b[39;00m param \u001b[39min\u001b[39;00m possible_kwargs\n\u001b[1;32m     91\u001b[0m     }\n\u001b[0;32m---> 92\u001b[0m     expression \u001b[39m=\u001b[39m rule(expression, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mrule_kwargs)\n\u001b[1;32m     94\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mcast(exp\u001b[39m.\u001b[39mExpression, expression)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/autosql-L2XNwnQu-py3.11/lib/python3.11/site-packages/sqlglot/optimizer/qualify.py:78\u001b[0m, in \u001b[0;36mqualify\u001b[0;34m(expression, dialect, db, catalog, schema, expand_alias_refs, infer_schema, isolate_tables, qualify_columns, validate_qualify_columns, quote_identifiers, identify)\u001b[0m\n\u001b[1;32m     75\u001b[0m     expression \u001b[39m=\u001b[39m quote_identifiers_func(expression, dialect\u001b[39m=\u001b[39mdialect, identify\u001b[39m=\u001b[39midentify)\n\u001b[1;32m     77\u001b[0m \u001b[39mif\u001b[39;00m validate_qualify_columns:\n\u001b[0;32m---> 78\u001b[0m     validate_qualify_columns_func(expression)\n\u001b[1;32m     80\u001b[0m \u001b[39mreturn\u001b[39;00m expression\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/autosql-L2XNwnQu-py3.11/lib/python3.11/site-packages/sqlglot/optimizer/qualify_columns.py:77\u001b[0m, in \u001b[0;36mvalidate_qualify_columns\u001b[0;34m(expression)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[39mif\u001b[39;00m scope\u001b[39m.\u001b[39mexternal_columns \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m scope\u001b[39m.\u001b[39mis_correlated_subquery \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m scope\u001b[39m.\u001b[39mpivots:\n\u001b[1;32m     76\u001b[0m             column \u001b[39m=\u001b[39m scope\u001b[39m.\u001b[39mexternal_columns[\u001b[39m0\u001b[39m]\n\u001b[0;32m---> 77\u001b[0m             \u001b[39mraise\u001b[39;00m OptimizeError(\n\u001b[1;32m     78\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\"\"\u001b[39m\u001b[39mColumn \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mcolumn\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m could not be resolved\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m for table: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mcolumn\u001b[39m.\u001b[39mtable\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39mif\u001b[39;00m\u001b[39m \u001b[39mcolumn\u001b[39m.\u001b[39mtable\u001b[39m \u001b[39m\u001b[39melse\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m     79\u001b[0m             )\n\u001b[1;32m     81\u001b[0m \u001b[39mif\u001b[39;00m unqualified_columns:\n\u001b[1;32m     82\u001b[0m     \u001b[39mraise\u001b[39;00m OptimizeError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAmbiguous columns: \u001b[39m\u001b[39m{\u001b[39;00munqualified_columns\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mOptimizeError\u001b[0m: Column '\"western kentucky\"' could not be resolved"
     ]
    }
   ],
   "source": [
    "execute(query, tables=table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['answer', 'context', 'question', 'table_count', 'column_types', 'duplicate_create_table', 'filler_data', 'query_result', 'valid_query'],\n",
       "    num_rows: 2799\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invalid_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': \"SELECT party FROM driver WHERE home_city = 'Hartford' AND age > 40\",\n",
       " 'context': 'CREATE TABLE driver (party VARCHAR, home_city VARCHAR, age VARCHAR)',\n",
       " 'question': 'Show the party with drivers from Hartford and drivers older than 40.',\n",
       " 'table_count': 1,\n",
       " 'column_types': '{\"driver\": {\"party\": \"VARCHAR\", \"home_city\": \"VARCHAR\", \"age\": \"VARCHAR\"}}',\n",
       " 'duplicate_create_table': False,\n",
       " 'filler_data': '{\"driver\": [{\"party\": \"Joseph Strickland\", \"home_city\": \"John Hamilton\", \"age\": \"Steven Rhodes\"}, {\"party\": \"Lisa Sanchez\", \"home_city\": \"Daniel Paul\", \"age\": \"Anthony Walsh\"}, {\"party\": \"Edwin Davis\", \"home_city\": \"Joshua Franco\", \"age\": \"Scott Jenkins\"}, {\"party\": \"Raymond Boyer\", \"home_city\": \"Zachary Cain\", \"age\": \"Jacqueline Young\"}, {\"party\": \"Cody Ramos\", \"home_city\": \"Gabriela Henson\", \"age\": \"Phyllis Anderson\"}]}',\n",
       " 'query_result': 'ExecuteError',\n",
       " 'valid_query': False}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invalid_queries[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df54d71a64c4778aadcb7f20f9b09a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2799 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "non_execute_error = invalid_queries.filter(lambda x: x['query_result'] != 'ExecuteError')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e3edc336ea544c89e526c9e90371254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/201 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['answer', 'context', 'question', 'table_count', 'column_types', 'duplicate_create_table', 'filler_data', 'query_result', 'valid_query'],\n",
       "    num_rows: 0\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_execute_error.filter(lambda x: x['query_result'] != 'ParseError')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'SELECT MIN(2002 AS _population) FROM table_13764346_1',\n",
       " 'context': 'CREATE TABLE table_13764346_1 (Id VARCHAR)',\n",
       " 'question': 'What is the smallest population recorded back in 2002?',\n",
       " 'table_count': 1,\n",
       " 'column_types': '{\"table_13764346_1\": {\"Id\": \"VARCHAR\"}}',\n",
       " 'duplicate_create_table': False,\n",
       " 'filler_data': '{\"table_13764346_1\": [{\"Id\": \"Kathleen Burns\"}, {\"Id\": \"Jared West\"}, {\"Id\": \"Jacqueline Smith\"}, {\"Id\": \"Curtis Thomas\"}, {\"Id\": \"Charles Mcbride\"}]}',\n",
       " 'query_result': 'ParseError',\n",
       " 'valid_query': False}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_execute_error[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoSQL",
   "language": "python",
   "name": "autosql"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
